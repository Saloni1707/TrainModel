{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnBF/RMtkO5XJJZFLTHmnF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saloni1707/TrainModel/blob/main/TTSagentLangraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axNEfYjlYmki",
        "outputId": "80d62c0a-d745-46da-dce4-11e09d588b34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your key: ··········\n"
          ]
        }
      ],
      "source": [
        "from typing import TypedDict\n",
        "from langgraph.graph import StateGraph,END\n",
        "from IPython.display import display,Audio,Markdown\n",
        "from openai import OpenAI\n",
        "from getpass import getpass\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"]=getpass(\"Enter your key: \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI()\n",
        "class AgentState(TypedDict):\n",
        "  input_text:str\n",
        "  processed_text:str\n",
        "  audio_data:bytes\n",
        "  audio_path:str\n",
        "  content_type:str"
      ],
      "metadata": {
        "id": "SrE9oyJgafjF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Node functions\n",
        "import io\n",
        "import tempfile\n",
        "def classify_input(state:AgentState) -> AgentState:\n",
        "  response=client.chat.completions.create(\n",
        "  model=\"gpt-4o-mini\",\n",
        "  messages=[\n",
        "      {\"role\":\"system\",\"content\":\"Classify the content as one of:'general','poem','news','joke'.\"},\n",
        "      {\"role\":\"user\",\"content\":state[\"input_text\"]}\n",
        "    ]\n",
        "  )\n",
        "  state[\"content_type\"]=response.choices[0].message.content.strip().lower()\n",
        "  return state\n",
        "\n",
        "def process_general(state:AgentState) -> AgentState:\n",
        "  state[\"processed_text\"]=state[\"input_text\"]\n",
        "  return state\n",
        "\n",
        "def process_poems(state:AgentState) -> AgentState:\n",
        "  response=client.chat.completions.create(\n",
        "      model=\"gpt-4o-mini\",\n",
        "      messages=[\n",
        "          {\"role\":\"system\",\"content\":\"Rewrite the following text as a short, beautiful poem:\"},\n",
        "          {\"role\":\"user\",\"content\":state[\"input_text\"]}\n",
        "      ]\n",
        "  )\n",
        "  state[\"processed_text\"]=response.choices[0].message.content.strip()\n",
        "  return state\n",
        "\n",
        "def process_news(state: AgentState) -> AgentState:\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Rewrite the following text in a formal news anchor style:\"},\n",
        "            {\"role\": \"user\", \"content\": state[\"input_text\"]}\n",
        "        ]\n",
        "    )\n",
        "    state[\"processed_text\"] = response.choices[0].message.content.strip()\n",
        "    return state\n",
        "\n",
        "def process_joke(state:AgentState) -> AgentState:\n",
        "    response=client.chat.completions.create(\n",
        "      model=\"gpt-4o-mini\",\n",
        "      messages=[\n",
        "        {\"role\":\"system\",\"content\":\"Turn the following text into a short, funny joke:\"},\n",
        "        {\"role\":\"user\",\"content\":state[\"input_text\"]}\n",
        "      ]\n",
        "    )\n",
        "    state[\"processed_text\"]=response.choices[0].message.content.strip()\n",
        "    return state\n",
        "\n",
        "def text_to_speech(state:AgentState,save_file:bool=False) -> AgentState:\n",
        "  voice_map={\n",
        "      \"general\":\"alloy\",\n",
        "      \"poem\":\"nova\",\n",
        "      \"news\":\"onyx\",\n",
        "      \"joke\":\"shimmer\"\n",
        "  }\n",
        "  voice = voice_map.get(state[\"content_type\"],\"alloy\")\n",
        "  audio_data=io.BytesIO()\n",
        "\n",
        "  with client.audio.speech.with_streaming_response.create(\n",
        "      model=\"tts-1\",\n",
        "      voice=voice,\n",
        "      input=state[\"processed_text\"]\n",
        "  ) as response:\n",
        "    for chunk in response.iter_bytes():\n",
        "      audio_data.write(chunk)\n",
        "\n",
        "    state[\"audio_data\"]= audio_data.getvalue()\n",
        "\n",
        "    if save_file:\n",
        "      with tempfile.NamedTemporaryFile(delete=False,suffix=\".mp3\") as temp_audio:\n",
        "        temp_audio.write(state[\"audio_data\"])\n",
        "        state[\"audio_path\"]=temp_audio.name\n",
        "  return state"
      ],
      "metadata": {
        "id": "W8nNVmd5bl76"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "#Langgraph pipeline here\n",
        "workflow=StateGraph(AgentState)\n",
        "workflow.add_node(\"classify_input\",classify_input)\n",
        "workflow.add_node(\"process_general\",process_general)\n",
        "workflow.add_node(\"process_poems\",process_poems)\n",
        "workflow.add_node(\"process_news\",process_news)\n",
        "workflow.add_node(\"process_joke\",process_joke)\n",
        "workflow.add_node(\"text_to_speech\",text_to_speech)\n",
        "\n",
        "#set the entry point of the graph\n",
        "workflow.set_entry_point(\"classify_input\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"classify_input\",\n",
        "    lambda x:x[\"content_type\"],{\n",
        "        \"general\":\"process_general\",\n",
        "        \"poem\":\"process_poems\",\n",
        "        \"news\":\"process_news\",\n",
        "        \"joke\":\"process_joke\"\n",
        "    }\n",
        ")\n",
        "\n",
        "#attach the process to TTS\n",
        "workflow.add_edge(\"process_general\",\"text_to_speech\")\n",
        "workflow.add_edge(\"process_poems\",\"text_to_speech\")\n",
        "workflow.add_edge(\"process_news\",\"text_to_speech\")\n",
        "workflow.add_edge(\"process_joke\",\"text_to_speech\")\n",
        "#compile the graph here\n",
        "app = workflow.compile() # Compiled the workflow and assigned to app"
      ],
      "metadata": {
        "id": "-EZpV__dlxNI"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def filename(text, max_length=20):\n",
        "    \"\"\"Convert text to a valid and concise filename.\"\"\"\n",
        "    sanitized = re.sub(r'[^\\w\\s-]', '', text.lower())\n",
        "    sanitized = re.sub(r'[-\\s]+', '_', sanitized)\n",
        "    return sanitized[:max_length]"
      ],
      "metadata": {
        "id": "qgvRfwIVmLoU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_tts(input_text:str,content_type:str,save_file:bool=True):\n",
        "  result=app.invoke({ # Corrected app.invoke to workflow.invoke\n",
        "      \"input_text\":input_text,\n",
        "      \"processed_text\":\"\",\n",
        "      \"audio_data\":\"\",\n",
        "      \"audio_path\":\"\",\n",
        "      \"content_type\":content_type\n",
        "  })\n",
        "  print(f\"Type of your content:{result['content_type']}\")\n",
        "  print(f\"Processed Text:{result['processed_text']}\")\n",
        "\n",
        "  display(Audio(result['audio_data'],autoplay=True))\n",
        "  if save_file:\n",
        "    audio_dir=os.path.join('..','audio')\n",
        "    os.makedirs(audio_dir,exist_ok=True)\n",
        "    filen=filename(input_text)\n",
        "    file_name=f\"{content_type}_{filen}.mp3\"\n",
        "    file_path=os.path.join(audio_dir,file_name)\n",
        "    with open(file_path,'wb') as f:\n",
        "      f.write(result['audio_data'])\n",
        "    print(f\"Audio saved at:{file_path}\")\n",
        "    github_relative_path = f\"../audio/{file_name}\"#path for github\n",
        "    display(Markdown(f\"[Download {content_type} audio: {filen}]({github_relative_path})\"))\n",
        "    print(\"Audio playback not supported here\")\n",
        "  else:\n",
        "    print(\"Audio not saved\")\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "IA_6Mp4elRhO"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = {\n",
        "    \"general\": \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"poem\": \"Roses are red, violets are blue, AI is amazing, and so are you!\",\n",
        "    \"news\": \"Breaking news: Scientists discover a new species of deep-sea creature in the Mariana Trench.\",\n",
        "    \"joke\": \"Why don't scientists trust atoms? Because they make up everything!\"\n",
        "}\n",
        "for content_type,text in examples.items():\n",
        "      print(f\"\\nProcessing example for {content_type} content:\")\n",
        "      print(f\"Input text: {text}\")\n",
        "      result=run_tts(text,content_type,save_file=True)\n",
        "      print(\"-\"*30)\n",
        "\n",
        "print(\"All downloads processed!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "vv8DBXxwzf2z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}